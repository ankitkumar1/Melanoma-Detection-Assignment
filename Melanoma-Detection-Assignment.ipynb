{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c57edd87",
   "metadata": {},
   "source": [
    "Problem statement: To build a CNN based model which can accurately detect melanoma. Melanoma is a type of cancer that can be deadly if not detected early. It accounts for 75% of skin cancer deaths. A solution that can evaluate images and alert dermatologists about the presence of melanoma has the potential to reduce a lot of manual effort needed in diagnosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20b87545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout,BatchNormalization\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1485f6cc",
   "metadata": {},
   "source": [
    "# Step 1: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1cf2678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is Train and test data/images in images folder\n",
    "data_dir_train = pathlib.Path(\"images\\Train\")\n",
    "data_dir_test = pathlib.Path('images\\Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78a75b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2239\n",
      "118\n"
     ]
    }
   ],
   "source": [
    "image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\n",
    "print(image_count_train)\n",
    "image_count_test = len(list(data_dir_test.glob('*/*.jpg')))\n",
    "print(image_count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "345c8954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desinging some parameters to create a dataset.\n",
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11acb30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2239 files belonging to 9 classes.\n",
      "Using 1792 files for training.\n",
      "Found 2239 files belonging to 9 classes.\n",
      "Using 447 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Using 80:20 for training and test/validate the trained data\n",
    "# Train DataSet\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  seed=123,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "# Valiadtion/test Data set\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  seed=123,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27d4d7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['actinic keratosis',\n",
       " 'basal cell carcinoma',\n",
       " 'dermatofibroma',\n",
       " 'melanoma',\n",
       " 'nevus',\n",
       " 'pigmented benign keratosis',\n",
       " 'seborrheic keratosis',\n",
       " 'squamous cell carcinoma',\n",
       " 'vascular lesion']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List out all the classes of skin cancer and store them in a list. \n",
    "class_names = train_ds.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4d1603",
   "metadata": {},
   "source": [
    "# Step 2 : Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812a31c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "  plt.subplot(3,3,i+1)\n",
    "  image = plt.imread(\n",
    "      str(list(data_dir_train.glob(f'{class_names[i]}/*.jpg'))[1]))\n",
    "  plt.title(class_names[i])\n",
    "  plt.imshow(image)\n",
    "  plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027b3a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "# Dataset.cache() method keeps the images in memory.\n",
    "Dataset.prefetch() overlaps data preprocessing and model execution while training.\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "#Dataset.prefetch() method overlaps data preprocessing and model execution while training.\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f175598d",
   "metadata": {},
   "source": [
    "# Step 3: Now Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a43573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a CNN model to accurately detect 9 classes present in the dataset\n",
    "model = Sequential()\n",
    "model.add(layers.Rescaling(1./255, input_shape=(img_height, img_width,3)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),padding = 'Same',activation= 'relu'))\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add(Conv2D(16, kernel_size=(7, 7),padding = 'Same',activation= 'relu'))\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, kernel_size=(11,11),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(256, kernel_size=(3, 3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(9,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f05360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an appropirate optimiser and loss function for model training\n",
    "learn_control = ReduceLROnPlateau(monitor='val_accuracy', patience=5,\n",
    "                                  verbose=1,factor=0.2, min_lr=1e-7)\n",
    "opt=tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84d549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208db286",
   "metadata": {},
   "source": [
    "## Step 3.1: Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98246427",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs,\n",
    "              callbacks=[learn_control]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d751c1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the training resultset\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0adf3b",
   "metadata": {},
   "source": [
    "# Finding so far after the training data\n",
    "- Training loss is very low, but validation loss is fluctuating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ce178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sfter we analysed the model fit history for presence of underfit or overfit, choose an appropriate data augumentation strategy. \n",
    "# augumentation strategy with flip,rotate,skew,shift, zoom, brightness, contrast, saturation, hue\n",
    "data_augmentation = tf.keras.Sequential(\n",
    "  [\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\", \n",
    "                                                 input_shape=(img_height, \n",
    "                                                              img_width,\n",
    "                                                              3)),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "    layers.experimental.preprocessing.RandomContrast(0.1)\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd42b8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how your augmentation strategy works for one instance of training image.\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    augmented_images = data_augmentation(images)\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2926e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width,3)))\n",
    "model.add(data_augmentation)\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),padding = 'Same',activation= 'relu'))\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add(Conv2D(16, kernel_size=(7, 7),padding = 'Same',activation= 'relu'))\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, kernel_size=(11, 11),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(256, kernel_size=(3, 3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(9,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccd6769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "learn_control = ReduceLROnPlateau(monitor='val_accuracy', patience=5,\n",
    "                                  verbose=1,factor=0.2, min_lr=1e-7)\n",
    "opt=tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3adf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d904ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "epochs = 20\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs,\n",
    "              callbacks=[learn_control]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99330a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the result for above model\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff66f076",
   "metadata": {},
   "source": [
    "### Findings\n",
    "- The Training accuracy and validation accuracy are almost same. This is a sign of good fit but the accuracy is still very low. The model requires more epochs to train with class imbalance handled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b0608c",
   "metadata": {},
   "source": [
    "## Find the distribution of classes in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b197b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images in each classes\n",
    "class_diff=pd.DataFrame()\n",
    "for i in range(len(class_names)):\n",
    "  name= class_names[i]\n",
    "  number = len(list(data_dir_train.glob(f'{class_names[i]}/*.jpg')))\n",
    "  class_diff=class_diff.append({'class':name,'number':number},ignore_index=True)\n",
    "\n",
    "class_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9162129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_diff.plot.bar(x='class',y='number',rot=90)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f601b7",
   "metadata": {},
   "source": [
    "## Findings so far\n",
    "1) Seborrheic keratosis (77) has the least number of samples\n",
    "2) Pigmented benign keratosis (462) classes dominate the data in terms proportionate number of samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0573df8b",
   "metadata": {},
   "source": [
    "## Rectify the class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823534b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use Augmentor to rectify the class imbalance.\n",
    "class_names=['actinic keratosis', 'basal cell carcinoma', 'dermatofibroma', 'melanoma', 'nevus', 'pigmented benign keratosis', 'seborrheic keratosis', 'squamous cell carcinoma', 'vascular lesion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899e27b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_training_dataset=\"images/Train/\"\n",
    "import Augmentor\n",
    "for i in class_names:\n",
    "    p = Augmentor.Pipeline(path_to_training_dataset + i)\n",
    "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
    "    p.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59e6db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count_train = len(list(data_dir_train.glob('*/output/*.jpg')))\n",
    "print(image_count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6da80b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dee3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training dataset\n",
    "\n",
    "data_dir_train=\"images/Train\"\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  seed=123,\n",
    "  validation_split = 0.2,\n",
    "  subset = \"training\",\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "# Create a validation dataset\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  seed=123,\n",
    "  validation_split = 0.2,\n",
    "  subset = \"validation\",\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479ddbb9",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c56789",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.experimental.preprocessing.Rescaling(1./255,input_shape=(180,180,3))) \n",
    "model.add(layers.Conv2D(32,kernel_size=(3,3),activation='relu'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(layers.Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(layers.Conv2D(128,kernel_size=(3,3),activation='relu'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(layers.Conv2D(256,kernel_size=(11,11),activation='relu'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(len(class_names),activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c12e70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "learn_control = ReduceLROnPlateau(monitor='val_accuracy', patience=5,\n",
    "                                  verbose=1,factor=0.2, min_lr=1e-7)\n",
    "opt=tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721afdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c701e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "epochs = 50\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs,\n",
    "              callbacks=[learn_control]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225344d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the model results\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf823e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "Test_image_path = os.path.join(data_dir_test, class_names[1], '*')\n",
    "Test_image = glob(Test_image_path)\n",
    "Test_image = load_img(Test_image[-1],target_size=(180,180,3))\n",
    "plt.imshow(Test_image)\n",
    "plt.grid(False)\n",
    "\n",
    "img = np.expand_dims(Test_image,axis=0)\n",
    "pred = model.predict(img)\n",
    "pred = np.argmax(pred)\n",
    "pred_class = class_names[pred]\n",
    "print(f\"Actual Class: {class_names[1]}\" + '\\n' + \"Predictive Class: \" + pred_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
